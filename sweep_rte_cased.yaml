program: /home/ubuntu/transformers/examples/text-classification/run_glue.py
command:
  - ${env}
  - python3
  - ${program}
  - "--do_train" 
  - "--do_eval" 
  - "--evaluate_during_training" 
  - "--overwrite_output_dir"
  - ${args}
method: grid
metric:
  name: eval_acc
  goal: maximize
parameters:
  #
  # parameters to be optimized over
  #
  learning_rate:
    value: 5e-5   # see Appendix of ALBERT paper
  per_device_train_batch_size:
    values: [8, 16, 32]
  max_seq_length:
    values: [128, 256, 512]
  model_name_or_path:
    values: ["bert-base-cased", 
    "distilbert-base-cased"]
  #
  # fixed parameters
  #
  task_name: 
    value: RTE
  data_dir: 
    value: /home/ubuntu/RTE 
  output_dir: 
    value: /tmp/RTE/
  num_train_epochs:
    value: 1
  logging_steps:
    value: 50
  weight_decay:
    value: .01
  adam_epsilon:
    value: 1e-6
  finetuning_iters:
    value: 5